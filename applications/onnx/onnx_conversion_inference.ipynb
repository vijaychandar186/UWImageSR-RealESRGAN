{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Td3xp0CFeQQc"
      },
      "outputs": [],
      "source": [
        "!pip install -q onnx onnxruntime-gpu basicsr  # Use onnxruntime-gpu for GPU systems; use onnxruntime for CPU-only systems"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5FNxCP7fsJv",
        "outputId": "0384187b-3c5a-4761-a7d9-df4db8a4621b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: basicsr\n",
            "Version: 1.4.2\n",
            "Summary: Open Source Image and Video Super-Resolution Toolbox\n",
            "Home-page: https://github.com/xinntao/BasicSR\n",
            "Author: Xintao Wang\n",
            "Author-email: xintao.wang@outlook.com\n",
            "License: Apache License 2.0\n",
            "Location: /usr/local/python/3.12.1/lib/python3.12/site-packages\n",
            "Requires: addict, future, lmdb, numpy, opencv-python, Pillow, pyyaml, requests, scikit-image, scipy, tb-nightly, torch, torchvision, tqdm, yapf\n",
            "Required-by: \n"
          ]
        }
      ],
      "source": [
        "!pip show basicsr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGjHL4ZjgPYo",
        "outputId": "4dd2a2f2-039e-4f65-d204-285dbb1af91f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing dependency-fix.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile dependency-fix.sh\n",
        "#!/bin/bash\n",
        "# Fix torchvision import in basicsr/data/degradations.py using relative path\n",
        "sed -i 's/from torchvision.transforms.functional_tensor import rgb_to_grayscale/from torchvision.transforms.functional import rgb_to_grayscale/' /usr/local/python/3.12.1/lib/python3.12/site-packages/basicsr/data/degradations.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7H1iQt70gbNj"
      },
      "outputs": [],
      "source": [
        "!chmod +x dependency-fix.sh\n",
        "!./dependency-fix.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiPQCYVJfVro",
        "outputId": "7235329f-688a-4517-a8f7-7c8bce898b1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "network_g config: {'num_in_ch': 3, 'num_out_ch': 3, 'num_feat': 64, 'num_block': 23, 'num_grow_ch': 32}\n",
            "Done! Exported to ../../RealESRGAN/model/net_g_5000.onnx\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "import torch\n",
        "import torch.onnx\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "\n",
        "def main():\n",
        "    # Configuration\n",
        "    input_model_path = '../../RealESRGAN/model/net_g_5000.pth'\n",
        "    output_onnx_path = '../../RealESRGAN/model/net_g_5000.onnx'\n",
        "    config_path = 'config.yml'\n",
        "    opset_version = 11\n",
        "    use_params_ema = True  # Set to False to use params instead of params_ema\n",
        "\n",
        "    # Load model configuration\n",
        "    with open(config_path, 'r') as reader:\n",
        "        config = yaml.load(reader, Loader=yaml.FullLoader)\n",
        "    print('network_g config:', config['network_g'])\n",
        "\n",
        "    # Initialize model\n",
        "    model = RRDBNet(\n",
        "        num_in_ch=config['network_g']['num_in_ch'],\n",
        "        num_out_ch=config['network_g']['num_out_ch'],\n",
        "        num_feat=config['network_g']['num_feat'],\n",
        "        num_block=config['network_g']['num_block'],\n",
        "        num_grow_ch=config['network_g']['num_grow_ch'],\n",
        "        scale=config['scale']\n",
        "    )\n",
        "\n",
        "    # Load model weights\n",
        "    keyname = 'params_ema' if use_params_ema else 'params'\n",
        "    model.load_state_dict(torch.load(input_model_path)[keyname])\n",
        "    model.cpu().eval()\n",
        "\n",
        "    # Create example input\n",
        "    x = torch.rand(1, 3, config['network_g']['num_feat'], config['network_g']['num_feat'])\n",
        "\n",
        "    # Export to ONNX\n",
        "    with torch.no_grad():\n",
        "        torch_out = torch.onnx.export(\n",
        "            model, x, output_onnx_path,\n",
        "            opset_version=opset_version,\n",
        "            export_params=True,\n",
        "            input_names=['input'],\n",
        "            output_names=['output'],\n",
        "            dynamic_axes={\n",
        "                'input': {0: 'batch_size', 2: 'height', 3: 'width'},\n",
        "                'output': {0: 'batch_size', 2: 'height', 3: 'width'}\n",
        "            }\n",
        "        )\n",
        "    print(f\"Done! Exported to {output_onnx_path}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbkBjwtrhJnD",
        "outputId": "7f690014-447c-4424-d6d3-bd1e87530c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Loading model from: ../../RealESRGAN/model/net_g_5000.onnx\n",
            "[INFO] Reading input image: input.png\n",
            "[INFO] Starting enhancement...\n",
            "\tTile 1/6\n",
            "\tTile 2/6\n",
            "\tTile 3/6\n",
            "\tTile 4/6\n",
            "\tTile 5/6\n",
            "\tTile 6/6\n",
            "[INFO] Enhancement completed in 275.85 seconds\n",
            "[SUCCESS] Enhanced image saved to: output.png\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import time\n",
        "from typing import Optional, Tuple, List\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "\n",
        "\n",
        "class BaseModel:\n",
        "    \"\"\" Inference with ONNXRuntime\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 model_path: str,\n",
        "                 intra_op_num_threads: int = -1,\n",
        "                 providers: List[str] = ['CPUExecutionProvider']):\n",
        "        \"\"\" Initializer\n",
        "        Args:\n",
        "          model_path (str): path to model\n",
        "          intra_op_num_threads (int): num threads, defaults to -1\n",
        "          providers (List[str]): onnxruntime providers, defaults to ['CPUExecutionProvider']\n",
        "        \"\"\"\n",
        "        if intra_op_num_threads > 0:\n",
        "            sess_options = ort.SessionOptions()\n",
        "            sess_options.intra_op_num_threads = intra_op_num_threads\n",
        "            self.sess = ort.InferenceSession(model_path, sess_options, providers=providers)\n",
        "        else:\n",
        "            self.sess = ort.InferenceSession(model_path, providers=providers)\n",
        "\n",
        "    def __call__(self, img: np.ndarray) -> np.ndarray:\n",
        "        input = self.sess.get_inputs()[0].name\n",
        "        output = self.sess.get_outputs()[0].name\n",
        "        return self.sess.run([output], {input: img})[0]\n",
        "\n",
        "\n",
        "class RealESRGAN:\n",
        "    def __init__(self,\n",
        "                 model_path: str,\n",
        "                 scale: int = 4,\n",
        "                 tile: int = 0,\n",
        "                 tile_pad: int = 10,\n",
        "                 pre_pad: int = 10,\n",
        "                 verbose: bool = True,\n",
        "                 **kwargs):\n",
        "        \"\"\"A helper class for upsampling images with RealESRGAN.\n",
        "        Args:\n",
        "            model_path (str): The path to the pretrained model.\n",
        "            scale (int): Upsampling scale factor used in the networks. It is usually 2 or 4.\n",
        "            tile (int): As too large images result in the out of GPU memory issue, so this tile option will first crop\n",
        "                input images into tiles, and then process each of them. Finally, they will be merged into one image.\n",
        "                0 denotes for do not use tile. Default: 0.\n",
        "            tile_pad (int): The pad size for each tile, to remove border artifacts. Default: 10.\n",
        "            pre_pad (int): Pad the input images to avoid border artifacts. Default: 10.\n",
        "            verbose (bool):  whether to verbose log. Default: True\n",
        "        \"\"\"\n",
        "        self.scale = scale\n",
        "        self.tile_size = tile\n",
        "        self.tile_pad = tile_pad\n",
        "        self.pre_pad = pre_pad\n",
        "        self.verbose = verbose\n",
        "        if self.scale == 2:\n",
        "            self.mod_scale = 2\n",
        "        elif self.scale == 1:\n",
        "            self.mod_scale = 4\n",
        "        else:\n",
        "            self.mod_scale = None\n",
        "        self.model = BaseModel(model_path, **kwargs)\n",
        "\n",
        "    def pre_process(self, img: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Pre-process, such as pre-pad and mod pad, so that the images can be divisible\n",
        "        \"\"\"\n",
        "        img = np.transpose(img, (2, 0, 1)).astype('float32')\n",
        "        img = np.expand_dims(img, 0)\n",
        "\n",
        "        # pre_pad\n",
        "        if self.pre_pad != 0:\n",
        "            img = np.pad(img, [(0, 0), (0, 0), (0, self.pre_pad), (0, self.pre_pad)], 'reflect')\n",
        "        # mod pad for divisible borders\n",
        "        if self.mod_scale is not None:\n",
        "            self.mod_pad_h, self.mod_pad_w = 0, 0\n",
        "            _, _, h, w = img.shape\n",
        "            if (h % self.mod_scale != 0):\n",
        "                self.mod_pad_h = (self.mod_scale - h % self.mod_scale)\n",
        "            if (w % self.mod_scale != 0):\n",
        "                self.mod_pad_w = (self.mod_scale - w % self.mod_scale)\n",
        "            img = np.pad(img, [(0, 0), (0, 0), (0, self.mod_pad_h), (0, self.mod_pad_w)], 'reflect')\n",
        "        return img\n",
        "\n",
        "    def predict(self, img: np.ndarray) -> np.ndarray:\n",
        "        # model inference\n",
        "        return self.model(img)\n",
        "\n",
        "    def tile_predict(self, img: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"It will first crop input images to tiles, and then process each tile.\n",
        "        Finally, all the processed tiles are merged into one images.\n",
        "        Modified from: https://github.com/ata4/esrgan-launcher\n",
        "        \"\"\"\n",
        "        batch, channel, height, width = img.shape\n",
        "        output_height = height * self.scale\n",
        "        output_width = width * self.scale\n",
        "        output_shape = (batch, channel, output_height, output_width)\n",
        "\n",
        "        # start with black image\n",
        "        output = np.zeros(output_shape)\n",
        "        tiles_x = math.ceil(width / self.tile_size)\n",
        "        tiles_y = math.ceil(height / self.tile_size)\n",
        "\n",
        "        # loop over all tiles\n",
        "        for y in range(tiles_y):\n",
        "            for x in range(tiles_x):\n",
        "                # extract tile from input image\n",
        "                ofs_x = x * self.tile_size\n",
        "                ofs_y = y * self.tile_size\n",
        "                # input tile area on total image\n",
        "                input_start_x = ofs_x\n",
        "                input_end_x = min(ofs_x + self.tile_size, width)\n",
        "                input_start_y = ofs_y\n",
        "                input_end_y = min(ofs_y + self.tile_size, height)\n",
        "\n",
        "                # input tile area on total image with padding\n",
        "                input_start_x_pad = max(input_start_x - self.tile_pad, 0)\n",
        "                input_end_x_pad = min(input_end_x + self.tile_pad, width)\n",
        "                input_start_y_pad = max(input_start_y - self.tile_pad, 0)\n",
        "                input_end_y_pad = min(input_end_y + self.tile_pad, height)\n",
        "\n",
        "                # input tile dimensions\n",
        "                input_tile_width = input_end_x - input_start_x\n",
        "                input_tile_height = input_end_y - input_start_y\n",
        "                tile_idx = y * tiles_x + x + 1\n",
        "                input_tile = img[:, :, input_start_y_pad:input_end_y_pad, input_start_x_pad:input_end_x_pad]\n",
        "\n",
        "                # upscale tile\n",
        "                try:\n",
        "                    output_tile = self.model(input_tile)\n",
        "                except RuntimeError as error:\n",
        "                    print('Error', error)\n",
        "                if self.verbose:\n",
        "                    print(f'\\tTile {tile_idx}/{tiles_x * tiles_y}')\n",
        "\n",
        "                # output tile area on total image\n",
        "                output_start_x = input_start_x * self.scale\n",
        "                output_end_x = input_end_x * self.scale\n",
        "                output_start_y = input_start_y * self.scale\n",
        "                output_end_y = input_end_y * self.scale\n",
        "\n",
        "                # output tile area without padding\n",
        "                output_start_x_tile = (input_start_x - input_start_x_pad) * self.scale\n",
        "                output_end_x_tile = output_start_x_tile + input_tile_width * self.scale\n",
        "                output_start_y_tile = (input_start_y - input_start_y_pad) * self.scale\n",
        "                output_end_y_tile = output_start_y_tile + input_tile_height * self.scale\n",
        "\n",
        "                # put tile into output image\n",
        "                output[:, :, output_start_y:output_end_y,\n",
        "                       output_start_x:output_end_x] = output_tile[:, :, output_start_y_tile:output_end_y_tile,\n",
        "                                                                  output_start_x_tile:output_end_x_tile]\n",
        "        return output\n",
        "\n",
        "    def post_process(self, output: np.ndarray) -> np.ndarray:\n",
        "        _, _, h, w = output.shape\n",
        "        # remove extra pad\n",
        "        if self.mod_scale is not None:\n",
        "            output = output[:, :, 0:h - self.mod_pad_h * self.scale, 0:w - self.mod_pad_w * self.scale]\n",
        "        # remove prepad\n",
        "        if self.pre_pad != 0:\n",
        "            output = output[:, :, 0:h - self.pre_pad * self.scale, 0:w - self.pre_pad * self.scale]\n",
        "        return output\n",
        "\n",
        "    def enhance(self,\n",
        "                img: np.ndarray,\n",
        "                outscale: Optional[int] = None,\n",
        "                alpha_upsampler: str = 'realesrgan') -> Tuple[np.ndarray, str]:\n",
        "        h_input, w_input = img.shape[0:2]\n",
        "        # img: numpy\n",
        "        img = img.astype(np.float32)\n",
        "        max_range = 65535 if np.max(img) > 256 else 255\n",
        "        img = img / max_range\n",
        "        if len(img.shape) == 2:  # gray image\n",
        "            img_mode = 'L'\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "        elif img.shape[2] == 4:  # RGBA image with alpha channel\n",
        "            img_mode = 'RGBA'\n",
        "            alpha = img[:, :, 3]\n",
        "            img = img[:, :, 0:3]\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            if alpha_upsampler == 'realesrgan':\n",
        "                alpha = cv2.cvtColor(alpha, cv2.COLOR_GRAY2RGB)\n",
        "        else:\n",
        "            img_mode = 'RGB'\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # process image (without the alpha channel)\n",
        "        img = self.pre_process(img)\n",
        "        if self.tile_size > 0:\n",
        "            logits = self.tile_predict(img)\n",
        "        else:\n",
        "            logits = self.predict(img)\n",
        "        output_img = self.post_process(logits)\n",
        "        output_img = np.clip(np.squeeze(output_img, 0), 0, 1)\n",
        "        output_img = np.transpose(output_img[[2, 1, 0], :, :], (1, 2, 0))\n",
        "        if img_mode == 'L':\n",
        "            output_img = cv2.cvtColor(output_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # process the alpha channel if necessary\n",
        "        if img_mode == 'RGBA':\n",
        "            if alpha_upsampler == 'realesrgan':\n",
        "                alpha_img = self.pre_process(alpha)\n",
        "                if self.tile_size > 0:\n",
        "                    logits = self.tile_predict(alpha_img)\n",
        "                else:\n",
        "                    logits = self.predict(alpha_img)\n",
        "                output_alpha = self.post_process(logits)\n",
        "                output_alpha = np.squeeze(output_alpha, 0)\n",
        "                output_alpha = np.transpose(output_alpha[[2, 1, 0], :, :], (1, 2, 0))\n",
        "                output_alpha = cv2.cvtColor(output_alpha, cv2.COLOR_RGB2GRAY)\n",
        "            else:  # use the cv2 resize for alpha channel\n",
        "                h, w = alpha.shape[0:2]\n",
        "                output_alpha = cv2.resize(alpha, (w * self.scale, h * self.scale), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "            # merge the alpha channel\n",
        "            output_img = cv2.cvtColor(output_img, cv2.COLOR_RGB2BGRA)\n",
        "            output_img[:, :, 3] = output_alpha\n",
        "\n",
        "        if max_range == 65535:  # 16-bit image\n",
        "            output = (output_img * 65535.0).round().astype(np.uint16)\n",
        "        else:\n",
        "            output = (output_img * 255.0).round().astype(np.uint8)\n",
        "\n",
        "        if outscale is not None and outscale != float(self.scale):\n",
        "            output = cv2.resize(\n",
        "                output, (\n",
        "                    int(w_input * outscale),\n",
        "                    int(h_input * outscale),\n",
        "                ), interpolation=cv2.INTER_LANCZOS4)\n",
        "\n",
        "        return output, img_mode\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Configuration\n",
        "    model_path = '../../RealESRGAN/model/net_g_5000.onnx'\n",
        "    input_path = 'input.png'\n",
        "    output_path = 'output.png'\n",
        "    output_scale = 4\n",
        "    tile_size = 400\n",
        "    num_threads = -1\n",
        "    providers = ['CPUExecutionProvider']\n",
        "\n",
        "    print(f\"[INFO] Loading model from: {model_path}\")\n",
        "    model = RealESRGAN(model_path, scale=output_scale, tile=tile_size, intra_op_num_threads=num_threads, providers=providers)\n",
        "\n",
        "    print(f\"[INFO] Reading input image: {input_path}\")\n",
        "    img = cv2.imread(input_path, cv2.IMREAD_UNCHANGED)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Could not read the input image from '{input_path}'\")\n",
        "\n",
        "    print(\"[INFO] Starting enhancement...\")\n",
        "    start_time = time.time()\n",
        "    output, _ = model.enhance(img, outscale=output_scale)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"[INFO] Enhancement completed in {elapsed_time:.2f} seconds\")\n",
        "\n",
        "    cv2.imwrite(output_path, output)\n",
        "    print(f\"[SUCCESS] Enhanced image saved to: {output_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
